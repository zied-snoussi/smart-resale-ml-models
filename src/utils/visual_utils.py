import matplotlib.pyplot as plt
import seaborn as sns
import os
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix, classification_report

# ==============================================================================
# CONFIGURATION GRAPHIQUE & ESTH√âTIQUE
# ==============================================================================

# Utilisation d'un style propre et moderne (ggplot) pour les pr√©sentations
plt.style.use('ggplot')

def plot_prediction_error(y_true, y_pred, save_path='static/plots'):
    """
    G√©n√®re un graphique de dispersion (Scatter Plot) comparant les valeurs r√©elles 
    et les pr√©dictions.
    
    Utilit√© : Visualiser visuellement la variance et identifier si le mod√®le 
    d√©croche sur les hautes valeurs (prix √©lev√©s).
    """
    os.makedirs(save_path, exist_ok=True)
    plt.figure(figsize=(10, 7))
    
    # Nuage de points avec alpha pour g√©rer la superposition (densit√©)
    sns.scatterplot(x=y_true, y=y_pred, alpha=0.4, color='#3498db')
    
    # Ligne de r√©f√©rence √† 45¬∞ : repr√©sente la pr√©diction id√©ale (y = x)
    max_val = max(max(y_true), max(y_pred))
    plt.plot([0, max_val], [0, max_val], color='#e74c3c', linestyle='--', lw=2, label='Pr√©diction Parfaite')
    
    plt.title('Pr√©cision de la R√©gression : R√©el vs Pr√©dit', fontsize=15)
    plt.xlabel('Prix R√©el (‚Ç¨)', fontsize=12)
    plt.ylabel('Prix Pr√©dit (‚Ç¨)', fontsize=12)
    plt.legend()
    
    output = os.path.join(save_path, 'prediction_error.png')
    plt.savefig(output, dpi=300) # R√©solution 300 DPI pour publication
    plt.close()
    print(f"üìà Graphique d'erreur de pr√©diction sauvegard√© : {output}")

def plot_confusion_matrix(y_true, y_pred, labels=["Low", "Mid", "High"], save_path='static/plots'):
    """
    G√©n√®re une matrice de confusion normalis√©e sous forme de Heatmap.
    
    Utilit√© : Identifier quelles cat√©gories de prix sont confondues par le mod√®le 
    (ex: un produit 'High' class√© en 'Mid').
    """
    # Calcul de la matrice et normalisation par ligne (pourcentages de rappel)
    cm = confusion_matrix(y_true, y_pred, labels=labels)
    cm_perc = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    plt.figure(figsize=(10, 8))
    sns.heatmap(cm_perc, annot=True, fmt='.1%', cmap='Blues', 
                xticklabels=labels, yticklabels=labels, annot_kws={"size": 14})
    
    plt.title('Matrice de Confusion (Pr√©cision par Tiers)', fontsize=15)
    plt.xlabel('Pr√©dictions du Mod√®le', fontsize=12)
    plt.ylabel('R√©alit√© (V√©rit√©)', fontsize=12)
    
    output = os.path.join(save_path, 'confusion_matrix_detailed.png')
    plt.savefig(output, dpi=300)
    plt.close()
    
    print(f"üìä Matrice de confusion sauvegard√©e : {output}")
    # Export du rapport textuel complet (F1-score, Recall, Precision)
    print("\n--- RAPPORT DE CLASSIFICATION D√âTAILL√â ---\n", classification_report(y_true, y_pred, target_names=labels))

def plot_error_distribution(y_true, y_pred, save_path='static/plots'):
    """
    Analyse de la distribution des r√©sidus (erreurs de pr√©diction).
    
    Utilit√© : V√©rifier l'homosc√©dasticit√© et l'absence de biais syst√©matique.
    Une distribution centr√©e sur 0 et sym√©trique indique un mod√®le sain.
    """
    errors = y_pred - y_true
    plt.figure(figsize=(10, 6))
    
    # Histogramme combin√© √† une estimation de la densit√© par noyau (KDE)
    sns.histplot(errors, kde=True, color='#9b59b6', bins=50)
    # Ligne d'erreur nulle
    plt.axvline(x=0, color='red', linestyle='--', lw=2)
    
    plt.title('Distribution de l\'Erreur (R√©sidus)', fontsize=15)
    plt.xlabel('Erreur (‚Ç¨) - [N√©gatif = Sous-estim√© | Positif = Surestim√©]', fontsize=12)
    plt.ylabel('Fr√©quence', fontsize=12)
    
    output = os.path.join(save_path, 'error_distribution.png')
    plt.savefig(output, dpi=300)
    plt.close()
    print(f"üìä Distribution des r√©sidus sauvegard√©e : {output}")

def plot_feature_importance(model, feature_names, save_path='static/plots'):
    """
    Visualisation de l'importance des variables (Feature Importance).
    
    Utilit√© : Expliquer le mod√®le ('Explainable AI'). Permet de savoir si 
    le mod√®le se base sur le MSRP, la marque ou l'√©tat pour d√©cider du prix.
    """
    # Extraction des poids d'importance sp√©cifiques aux mod√®les bas√©s sur les arbres
    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
        # Tri des 15 variables les plus impactantes
        indices = np.argsort(importances)[-15:] 
        
        plt.figure(figsize=(10, 8))
        plt.title('Top 15 des Variables Influentes', fontsize=15)
        plt.barh(range(len(indices)), importances[indices], color='#2ecc71', align='center')
        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])
        plt.xlabel('Importance Relative', fontsize=12)
        
        output = os.path.join(save_path, 'feature_importance.png')
        plt.savefig(output, dpi=300)
        plt.close()
        print(f"üìä Importance des variables sauvegard√©e : {output}")
import time
import logging
import sys
import os

# ==============================================================================
# 1. CONFIGURATION DE L'ENVIRONNEMENT ET DES CHEMINS
# ==============================================================================
# On s'assure que le r√©pertoire 'src' est dans le chemin syst√®me pour permettre
# les imports modulaires, peu importe d'o√π le script est lanc√©.
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

# Cr√©ation r√©cursive des dossiers pour les logs et les donn√©es si n√©cessaire
os.makedirs(os.path.join(current_dir, 'data', 'logs'), exist_ok=True)
log_file = os.path.join(current_dir, 'data', 'logs', 'pipeline_run.log')

# ==============================================================================
# 2. IMPORTATION DES √âTAPES DU PIPELINE
# ==============================================================================
from utils.download_datasets import download_and_extract
from pipeline.step1_prep import run_step1_preparation
from pipeline.step2_features import run_step2_features
from pipeline.step3_training import run_training_pipeline
from pipeline.step4_evaluation import run_step4_evaluation

# ==============================================================================
# 3. CONFIGURATION DU LOGGING (DOUBLE SORTIE : FICHIER ET CONSOLE)
# ==============================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file),      # Archive les logs pour l'audit
        logging.StreamHandler(sys.stdout)   # Affiche l'avancement en temps r√©el
    ]
)

def check_datasets():
    """
    √âtape 0 : V√©rification et Acquisition des donn√©es.
    V√©rifie la pr√©sence des fichiers bruts CSV. Si absents, d√©clenche le 
    t√©l√©chargement automatis√© depuis Kaggle via l'API.
    """
    ebay_file = 'data/raw/marketing_sample_for_ebay_com-ebay_com_product__20200601_20200831__30k_data.csv'
    amazon_file = 'data/raw/amazon_products.csv'
    
    # Construction des chemins relatifs √† la racine du projet
    root_ebay_path = os.path.join(current_dir, '..', ebay_file)
    root_amazon_path = os.path.join(current_dir, '..', amazon_file)

    if not os.path.exists(root_ebay_path) or not os.path.exists(root_amazon_path):
        logging.info("üì¶ Donn√©es brutes manquantes. Lancement du t√©l√©chargement Kaggle...")
        # Acquisition des datasets eBay et Amazon
        download_and_extract('promptcloud/ebay-product-listing', os.path.join(current_dir, '..', 'data/raw'))
        download_and_extract('aaronfriasr/amazon-products-dataset', os.path.join(current_dir, '..', 'data/raw'))
    else:
        logging.info("‚úÖ Datasets bruts d√©tect√©s. Passage √† l'√©tape suivante.")

def run_full_pipeline():
    """
    Ex√©cution compl√®te du workflow CRISP-DM.
    G√®re l'encha√Ænement logique des t√¢ches et mesure le temps d'ex√©cution total.
    """
    start_time = time.time()
    logging.info("üöÄ D√âMARRAGE DU PIPELINE COMPLET 'SMART RESALE'")
    
    
    
    try:
        # √âTAPE 0 : Acquisition (V√©rifie que les sources sont pr√™tes)
        check_datasets()

        # √âTAPE 1 : Pr√©paration (Nettoyage, Filtrage des Outliers, Fusion Amazon)
        run_step1_preparation()
        
        # √âTAPE 2 : Feature Engineering (NLP avec SVD, Scaling, Encodage)
        run_step2_features()
        
        # √âTAPE 3 : Entra√Ænement (Mod√®les Random Forest R√©gression & Classification)
        run_training_pipeline()
        
        # √âTAPE 4 : √âvaluation (G√©n√©ration des m√©triques et graphiques de diagnostic)
        run_step4_evaluation()
        
        total_time = time.time() - start_time
        logging.info(f"üéâ PIPELINE TERMIN√â AVEC SUCC√àS en {total_time:.2f} secondes !")

    except Exception as e:
        # En cas d'erreur, le traceback complet est captur√© dans les logs
        logging.error(f"‚ùå √âCHEC DU PIPELINE. D√©tails : {str(e)}")
        raise

if __name__ == "__main__":
    run_full_pipeline()
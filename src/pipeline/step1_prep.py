import pandas as pd
import os
import logging
from utils.load_data import load_ebay_data
from utils.preprocessing import preprocess_ebay_data
from utils.enrichment import enrich_ebay_with_amazon

# ==============================================================================
# CONFIGURATION DU LOGGING (TRAÃ‡ABILITÃ‰ PROFESSIONNELLE)
# ==============================================================================
# Le logging est essentiel en production pour surveiller l'Ã©tat du pipeline
# sans polluer la sortie standard uniquement avec des 'print'.
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)

def run_step1_preparation():
    """
    Ã‰TAPE 1 : PRÃ‰PARATION ET ENRICHISSEMENT DES DONNÃ‰ES
    --------------------------------------------------
    Objectif : Nettoyer les donnÃ©es brutes eBay et les fusionner avec les 
    rÃ©fÃ©rences de prix (MSRP) d'Amazon via un matching sÃ©mantique.
    """
    logging.info("ğŸš€ DÃ‰MARRAGE DE L'Ã‰TAPE 1 : PRÃ‰PARATION DES DONNÃ‰ES")

    # 1. CHARGEMENT DES DONNÃ‰ES BRUTES
    # Utilisation des utilitaires modulaires pour maintenir un code propre et lisible.
    logging.info("Extraction des donnÃ©es eBay depuis les sources locales...")
    df_raw = load_ebay_data()
    
    # 2. NETTOYAGE ET GESTION DES VALEURS ABERRANTES (OUTLIERS)
    # Cette Ã©tape convertit les prix en nombres et Ã©limine les annonces 
    # dont les prix sont irrÃ©alistes (ex: 0â‚¬ ou > 5000â‚¬).
    logging.info("Nettoyage des donnÃ©es et filtrage statistique des anomalies...")
    df_clean = preprocess_ebay_data(df_raw)

    # 3. ENRICHISSEMENT DES DONNÃ‰ES (MATCHING SÃ‰MANTIQUE)
    # Le "coeur" du projet : faire correspondre les objets eBay au catalogue Amazon 
    # pour obtenir le prix neuf et la popularitÃ© du produit.
    logging.info("Enrichissement via le catalogue Amazon (Vecteurs TF-IDF)...")
    df_enriched = enrich_ebay_with_amazon(df_clean)

    # 4. CONTRÃ”LE DE QUALITÃ‰ FINAL (SANITY FILTER)
    # Ã‰tape critique : On ne conserve que les lignes exploitables oÃ¹ le matching 
    # a rÃ©ussi et oÃ¹ le prix nettoyÃ© est prÃ©sent.
    df_final = df_enriched[df_enriched['price_cleaned'] > 0].copy()
    
    # 5. SAUVEGARDE DES ARTEFACTS TRAITÃ‰S
    # On crÃ©e le dossier de destination s'il n'existe pas.
    os.makedirs('data/processed', exist_ok=True)
    
    # Sauvegarde au format Pickle (plus rapide, conserve les types Python)
    # et CSV (format lisible par l'humain pour vÃ©rification manuelle).
    output_pickle = 'data/processed/ebay_prep.pkl'
    output_csv = 'data/processed/ebay_prep_debug.csv'
    
    df_final.to_pickle(output_pickle)
    df_final.to_csv(output_csv, index=False)
    
    logging.info(f"âœ… Ã‰tape 1 terminÃ©e avec succÃ¨s !")
    logging.info(f"ğŸ“Š Volume final : {df_final.shape[0]:,} produits prÃªts pour l'entraÃ®nement.")
    logging.info(f"ğŸ’¾ Fichiers sauvegardÃ©s dans : data/processed/")

if __name__ == "__main__":
    try:
        run_step1_preparation()
    except Exception as e:
        logging.error(f"âŒ Erreur critique lors du pipeline : {str(e)}")
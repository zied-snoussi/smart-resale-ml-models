import joblib
import os
import logging
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from utils.model_utils import save_artifact, get_price_bins

# Configuration du logging pour suivre l'avanc√©e de la recherche
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def run_training_pipeline():
    """
    √âTAPE 3 OPTIMIS√âE : HYPERPARAMETER TUNING (GRIDSEARCH)
    ----------------------------------------------------
    Objectif : Ne pas se contenter des r√©glages par d√©faut, mais tester 
    math√©matiquement les meilleures combinaisons d'arbres et de profondeur.
    """
    logging.info("üöÄ D√âMARRAGE DE L'ENTRA√éNEMENT OPTIMIS√â (GRIDSEARCH)")

    # 1. CHARGEMENT DES DONN√âES
    if not os.path.exists('data/processed/X_final.joblib'):
        logging.error("‚ùå Matrices X/y manquantes. Ex√©cutez l'√âtape 2 d'abord.")
        return

    X_train = joblib.load('data/processed/X_final.joblib')
    y_train = joblib.load('data/processed/y_final.joblib')

    # 2. D√âFINITION DE LA GRILLE DE PARAM√àTRES
    # On d√©finit les options que le mod√®le va tester
    param_grid = {
        'n_estimators': [100, 200],      # Nombre d'arbres dans la for√™t
        'max_depth': [10, 20, None],     # Profondeur des d√©cisions
        'min_samples_split': [2, 5],     # Nombre min d'√©chantillons pour diviser un n≈ìud
        'bootstrap': [True]              # M√©thode d'√©chantillonnage
    }

    # 3. OPTIMISATION DE LA R√âGRESSION
    logging.info("üîç Recherche des meilleurs param√®tres pour la R√©gression...")
    rf_reg = RandomForestRegressor(random_state=42)
    
    # GridSearchCV divise les donn√©es en 3 (cv=3) pour valider chaque combinaison
    grid_reg = GridSearchCV(
        estimator=rf_reg, 
        param_grid=param_grid, 
        cv=3, 
        n_jobs=-1, 
        scoring='neg_mean_absolute_error',
        verbose=1
    )
    grid_reg.fit(X_train, y_train)
    
    logging.info(f"‚ú® Meilleurs param√®tres R√©gression : {grid_reg.best_params_}")
    save_artifact(grid_reg.best_estimator_, "price_regressor")

    # 4. OPTIMISATION DE LA CLASSIFICATION
    logging.info("üîç Recherche des meilleurs param√®tres pour la Classification...")
    y_class = get_price_bins(y_train)
    rf_clf = RandomForestClassifier(random_state=42)
    
    grid_clf = GridSearchCV(
        estimator=rf_clf, 
        param_grid=param_grid, 
        cv=3, 
        n_jobs=-1, 
        scoring='accuracy',
        verbose=1
    )
    grid_clf.fit(X_train, y_class)
    
    logging.info(f"‚ú® Meilleurs param√®tres Classification : {grid_clf.best_params_}")
    save_artifact(grid_clf.best_estimator_, "price_classifier")

    logging.info("‚úÖ √âtape 3 termin√©e : Mod√®les optimis√©s sauvegard√©s.")

if __name__ == "__main__":
    run_training_pipeline()